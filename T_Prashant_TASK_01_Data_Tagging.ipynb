{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_Y4_2YVWhzW",
        "outputId": "f85f3ec1-6d79-4d1d-899a-f1853df149be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Collecting fuzzywuzzy\n",
            "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting rapidfuzz\n",
            "  Downloading rapidfuzz-3.12.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
            "Downloading rapidfuzz-3.12.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fuzzywuzzy, rapidfuzz\n",
            "Successfully installed fuzzywuzzy-0.18.0 rapidfuzz-3.12.1\n"
          ]
        }
      ],
      "source": [
        "pip install pandas nltk fuzzywuzzy  rapidfuzz"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from fuzzywuzzy import process\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fR7RnZNgXb5e",
        "outputId": "2068ec49-0d7b-4cd5-fa16-acea983380ff"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
            "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Excel file\n",
        "file_path = \"/content/DA_Task_1.xlsx\"\n",
        "\n",
        "# Read the sheet names\n",
        "xls = pd.ExcelFile(file_path)\n",
        "xls.sheet_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwzadvUHXeRC",
        "outputId": "73d25c62-a217-46c3-e54b-60d104976f7e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['complaints_data', 'taxonomy_sheet']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the complaints data and taxonomy sheet\n",
        "complaints_df = pd.read_excel(file_path, sheet_name=\"complaints_data\")\n",
        "taxonomy_df = pd.read_excel(file_path, sheet_name=\"taxonomy_sheet\")\n",
        "\n",
        "# Display the first few rows of each dataset\n",
        "complaints_sample = complaints_df.head()\n",
        "taxonomy_sample = taxonomy_df.head()\n",
        "\n",
        "complaints_sample, taxonomy_sample"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dw3piydHXpG9",
        "outputId": "d0ecea5c-3ed1-40b7-ba92-325a76138287"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(    Primary Key Order Date Product Category  \\\n",
              " 0   SO0026296-1 2023-03-08           SPRAYS   \n",
              " 1   SO0026385-1 2023-03-08           SPRAYS   \n",
              " 2  SO0026385-11 2023-03-08           SPRAYS   \n",
              " 3   SO0028352-1 2023-03-08           SPRAYS   \n",
              " 4   SO0028770-1 2023-03-08           SPRAYS   \n",
              " \n",
              "                                            Complaint  \\\n",
              " 0  VISIBLY NOTICE fasteners under cab on P clips ...   \n",
              " 1                       Fuel door will not stay open   \n",
              " 2   Compressor pressure line, braided steel, crushed   \n",
              " 3                 Oil running from bottom of machine   \n",
              " 4                   MISSING VECTOR & INTRIP UNLOCKS.   \n",
              " \n",
              "                                                Cause  \\\n",
              " 0                            Not tighten at factory.   \n",
              " 1     GAS STRUT NOT INSTALLED OR ANYWHERE ON MACHINE   \n",
              " 2  Compressor pressure line, braided steel, crush...   \n",
              " 3  OIL RETURN UNDER MACHINE SWIVEL FITTING LEFT L...   \n",
              " 4  MISSING VECTOR & INTRIP UNLOCKS WERE NOT INSTA...   \n",
              " \n",
              "                                           Correction     Root Cause  \\\n",
              " 0  GO THROUGH AND RE-TIGHTEN ALL P CLIPS, NUTS, A...  Not Tightened   \n",
              " 1  FOUND GAS STRUT NOT INSTALLED OR ANYWHERE ON M...  Not Installed   \n",
              " 2  DRAIN AIR FROM SYSTEM.REMOVE ASSOCIATED P CLIP...            NaN   \n",
              " 3  OIL RETURN UNDER MACHINE SWIVEL FITTING LEFT L...            NaN   \n",
              " 4          INSTALLED MISSING UNLOCKS RAN AND TESTED.            NaN   \n",
              " \n",
              "   Symptom Condition 1 Symptom Component 1 Symptom Condition 2  \\\n",
              " 0               Loose          Cab P Clip               Loose   \n",
              " 1     Won't stay open           Fuel Door                 NaN   \n",
              " 2                 NaN                 NaN                 NaN   \n",
              " 3                 NaN                 NaN                 NaN   \n",
              " 4                 NaN                 NaN                 NaN   \n",
              " \n",
              "   Symptom Component 2 Symptom Condition 3 Symptom Component 3 Fix Condition 1  \\\n",
              " 0       Left-Air Duct               Loose  Bulkhead Connector     Retightened   \n",
              " 1                 NaN                 NaN                 NaN       Installed   \n",
              " 2                 NaN                 NaN                 NaN             NaN   \n",
              " 3                 NaN                 NaN                 NaN             NaN   \n",
              " 4                 NaN                 NaN                 NaN             NaN   \n",
              " \n",
              "   Fix Component 1 Fix Condition 2 Fix Component 2 Fix Condition 3  \\\n",
              " 0      Cab P Clip     Retightened   Left Air Duct     Retightened   \n",
              " 1       Gas Strut             NaN             NaN             NaN   \n",
              " 2             NaN             NaN             NaN             NaN   \n",
              " 3             NaN             NaN             NaN             NaN   \n",
              " 4             NaN             NaN             NaN             NaN   \n",
              " \n",
              "       Fix Component 3  \n",
              " 0  Bulkhead Connector  \n",
              " 1                 NaN  \n",
              " 2                 NaN  \n",
              " 3                 NaN  \n",
              " 4                 NaN  ,\n",
              "       Root Cause Symptom Condition          Symptom Component  Fix Condition  \\\n",
              " 0  Not Tightened              Loose                Cab P Clip    Retightened   \n",
              " 1  Not Installed    Won't stay open                 Fuel Door      Installed   \n",
              " 2  Not Mentioned            Crushed  Compressor Pressure Line       Replaced   \n",
              " 3       Loosened        Oil Running             Not Mentioned     Topped Off   \n",
              " 4   Not Included            Missing                    Vector  Not Mentioned   \n",
              " \n",
              "    Fix Component  \n",
              " 0     Cab P Clip  \n",
              " 1      Gas Strut  \n",
              " 2  Braided Steel  \n",
              " 3         O-Ring  \n",
              " 4         Vector  )"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "complaints_df.info()\n",
        "\n",
        "taxonomy_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxmgNDWmXsPF",
        "outputId": "ce9f90a8-af56-4e84-f3c9-53304242d3ee"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 20 entries, 0 to 19\n",
            "Data columns (total 19 columns):\n",
            " #   Column               Non-Null Count  Dtype         \n",
            "---  ------               --------------  -----         \n",
            " 0   Primary Key          20 non-null     object        \n",
            " 1   Order Date           20 non-null     datetime64[ns]\n",
            " 2   Product Category     20 non-null     object        \n",
            " 3   Complaint            20 non-null     object        \n",
            " 4   Cause                20 non-null     object        \n",
            " 5   Correction           20 non-null     object        \n",
            " 6   Root Cause           2 non-null      object        \n",
            " 7   Symptom Condition 1  2 non-null      object        \n",
            " 8   Symptom Component 1  2 non-null      object        \n",
            " 9   Symptom Condition 2  1 non-null      object        \n",
            " 10  Symptom Component 2  1 non-null      object        \n",
            " 11  Symptom Condition 3  1 non-null      object        \n",
            " 12  Symptom Component 3  1 non-null      object        \n",
            " 13  Fix Condition 1      2 non-null      object        \n",
            " 14  Fix Component 1      2 non-null      object        \n",
            " 15  Fix Condition 2      1 non-null      object        \n",
            " 16  Fix Component 2      1 non-null      object        \n",
            " 17  Fix Condition 3      1 non-null      object        \n",
            " 18  Fix Component 3      1 non-null      object        \n",
            "dtypes: datetime64[ns](1), object(18)\n",
            "memory usage: 3.1+ KB\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 24 entries, 0 to 23\n",
            "Data columns (total 5 columns):\n",
            " #   Column              Non-Null Count  Dtype \n",
            "---  ------              --------------  ----- \n",
            " 0   Root Cause          18 non-null     object\n",
            " 1   Symptom Condition   17 non-null     object\n",
            " 2   Symptom Component   18 non-null     object\n",
            " 3   Fix Condition       9 non-null      object\n",
            " 4   Fix Component       24 non-null     object\n",
            "dtypes: object(5)\n",
            "memory usage: 1.1+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Select text-based columns for analysis\n",
        "text_columns = [\"Complaint\", \"Cause\",\"Correction\"]\n",
        "\n",
        "# Fill missing values with an empty string\n",
        "complaints_df[text_columns] = complaints_df[text_columns].fillna(\"\")"
      ],
      "metadata": {
        "id": "jDE9wM5WXvv6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    text = re.sub(r'\\W+', ' ', text)\n",
        "    text = text.strip()\n",
        "    return text\n",
        "\n",
        "# Apply cleaning\n",
        "for col in text_columns:\n",
        "    complaints_df[col] = complaints_df[col].apply(clean_text)"
      ],
      "metadata": {
        "id": "WNTRbCbFX0KL"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select text-based columns for analysis\n",
        "taxonomy_columns = [\"Root Cause\", \"Symptom Condition \",\"Symptom Component\", \"Fix Condition\", \"Fix Component\"]\n",
        "\n",
        "# Fill missing values with an empty string\n",
        "taxonomy_df[taxonomy_columns] = taxonomy_df[taxonomy_columns].fillna(taxonomy_df.mode())"
      ],
      "metadata": {
        "id": "UACAXBlXX3Tf"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Combine all text data into a single corpus\n",
        "corpus = complaints_df[\"Complaint\"].tolist() + complaints_df[\"Cause\"].tolist() + complaints_df[\"Correction\"].tolist()\n",
        "\n",
        "# Apply TF-IDF\n",
        "vectorizer = TfidfVectorizer(max_features=1000, stop_words=\"english\")\n",
        "tfidf_matrix = vectorizer.fit_transform(corpus)\n",
        "\n",
        "# Extract top keywords\n",
        "keywords = vectorizer.get_feature_names_out()\n",
        "print(\"Extracted Keywords:\", keywords)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TO5UbPg6X7hT",
        "outputId": "54b156ca-6f0a-4763-ee52-ffa68ab2b33b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted Keywords: ['ac' 'adapter' 'air' 'andnot' 'arrived' 'associated' 'auto' 'autoboom'\n",
            " 'backorder' 'began' 'block' 'blown' 'bolts' 'boom' 'boomrunning' 'booms'\n",
            " 'bosse' 'bracket' 'bracketpn' 'brackets' 'braided' 'broke' 'broken'\n",
            " 'bulk' 'bulkhead' 'cab' 'callstart' 'came' 'case' 'checked' 'cleaned'\n",
            " 'cleared' 'clips' 'cnh' 'code' 'codes' 'components' 'compressor'\n",
            " 'condenser' 'connect' 'connection' 'connections' 'connectors'\n",
            " 'contaminating' 'continue' 'control' 'cooler' 'coolers' 'counter'\n",
            " 'coupler' 'coupling' 'cradle' 'crushed' 'customer' 'cut' 'damaged'\n",
            " 'dealer' 'def' 'deliverd' 'depict' 'diagnose' 'did' 'disassemble' 'does'\n",
            " 'door' 'drain' 'drip' 'dripping' 'drive' 'drove' 'ducting' 'elb' 'elbow'\n",
            " 'end' 'engine' 'error' 'est' 'etim' 'factory' 'failed' 'farm' 'fast'\n",
            " 'fasteners' 'fault' 'faulty' 'field' 'filled' 'fitting' 'fittings'\n",
            " 'fittingunit' 'fold' 'folding' 'followed' 'frame' 'free' 'fuel' 'fully'\n",
            " 'gallons' 'gas' 'getting' 'glass' 'good' 'got' 'hammer' 'hand' 'harness'\n",
            " 'head' 'help' 'hitting' 'hood' 'hook' 'hooked' 'hose' 'hoses' 'housing'\n",
            " 'hrs' 'humidity' 'huron' 'hwy' 'hydraulic' 'included' 'inspected'\n",
            " 'install' 'installed' 'intake' 'internal' 'intrip' 'issue' 'kevin' 'key'\n",
            " 'kit' 'larger' 'leak' 'leaking' 'left' 'lh' 'light' 'line' 'loaded'\n",
            " 'location' 'locationinspected' 'locked' 'looked' 'looking' 'loose'\n",
            " 'lubricant' 'machine' 'machinepictures' 'male' 'massive' 'match'\n",
            " 'material' 'mid' 'mileage' 'miles' 'missing' 'module' 'mount' 'ncv'\n",
            " 'ncvs' 'necessaryalso' 'needed' 'new' 'node' 'notice' 'number'\n",
            " 'numbermatched' 'nuts' 'oil' 'old' 'open' 'operation' 'order' 'oring'\n",
            " 'outer' 'parts' 'pdi' 'peice' 'pins' 'pipe' 'pn' 'poor' 'powerup'\n",
            " 'pressure' 'product' 'pulled' 'pulling' 'pump' 'quality' 'quick' 'rail'\n",
            " 'ran' 'range' 'ranmachine' 'rear' 'recover' 'reinstall' 'released'\n",
            " 'remove' 'removed' 'repair' 'replace' 'replaced' 'reservoir' 'reset'\n",
            " 'resulting' 'retorque' 'return' 'right' 'ring' 'rinse' 'road' 'run'\n",
            " 'running' 'screwed' 'sd' 'seated' 'second' 'sender' 'sending' 'sensor'\n",
            " 'sensorautoboom' 'sensors' 'service' 'shop' 'sight' 'sign' 'smv' 'socket'\n",
            " 'software' 'sprayer' 'started' 'stay' 'steel' 'sticking' 'strut' 'supply'\n",
            " 'sure' 'swivel' 'tank' 'tap' 'tapped' 'tec' 'tech' 'test' 'tested'\n",
            " 'tests' 'th' 'thd' 'thread' 'threads' 'tie' 'tighten' 'tightened' 'time'\n",
            " 'tore' 'total' 'transducer' 'transferred' 'trial' 'tripremove'\n",
            " 'troubleshooting' 'truck' 'tube' 'turned' 'uncoupled' 'uneven' 'unfold'\n",
            " 'unhooked' 'unit' 'unitinspected' 'unitpn' 'unlocks' 'upunfolde' 'used'\n",
            " 'vector' 'verify' 'visibly' 'voltages' 'went' 'wi' 'wires' 'won' 'work'\n",
            " 'wrong' 'zip' 'zipties' '¼à']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "taxonomy_df.columns = taxonomy_df.columns.str.strip()"
      ],
      "metadata": {
        "id": "GdABFPInX_pB"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from rapidfuzz import process\n",
        "from fuzzywuzzy import process\n"
      ],
      "metadata": {
        "id": "u8BvIIJdYDLX"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tag_text(text, category_list, threshold=50):\n",
        "    if pd.isna(text):\n",
        "        return \"Unknown\"\n",
        "    text = str(text).strip()\n",
        "    if not text:\n",
        "        return \"Unknown\"\n",
        "\n",
        "    if not category_list:\n",
        "        return \"Unknown\"\n",
        "\n",
        "    best_match, score = process.extractOne(text, category_list, scorer=process.fuzz.WRatio)\n",
        "    return best_match if score > threshold else \"Unknown\"\n",
        "\n",
        "def extract_conditions_from_text(text, symptom_condition_list, symptom_component_list,\n",
        "                                  fix_condition_list, fix_component_list, root_cause_list):\n",
        "    \"\"\"Extract multiple conditions and components from text\"\"\"\n",
        "    conditions = []\n",
        "    components = []\n",
        "    root_causes = []\n",
        "\n",
        "    for condition in symptom_condition_list:\n",
        "        if process.extractOne(condition, [text], scorer=process.fuzz.WRatio)[1] > 50:\n",
        "            conditions.append(condition)\n",
        "    for component in symptom_component_list:\n",
        "        if process.extractOne(component, [text], scorer=process.fuzz.WRatio)[1] > 50:\n",
        "            components.append(component)\n",
        "    for condition in fix_condition_list:\n",
        "        if process.extractOne(condition, [text], scorer=process.fuzz.WRatio)[1] > 50:\n",
        "            conditions.append(condition)\n",
        "    for component in fix_component_list:\n",
        "        if process.extractOne(component, [text], scorer=process.fuzz.WRatio)[1] > 50:\n",
        "            components.append(component)\n",
        "    for root_cause in root_cause_list:\n",
        "        if process.extractOne(root_cause, [text], scorer=process.fuzz.WRatio)[1] > 50:\n",
        "            root_causes.append(root_cause)\n",
        "\n",
        "    return conditions, components, root_causes\n",
        "\n",
        "def process_complaints_data(complaints_df, taxonomy_df):\n",
        "    taxonomy_df = taxonomy_df.applymap(lambda x: str(x).strip().lower() if isinstance(x, str) else x)\n",
        "    symptom_condition_list = taxonomy_df[\"Symptom Condition\"].dropna().unique().tolist()\n",
        "    symptom_component_list = taxonomy_df[\"Symptom Component\"].dropna().unique().tolist()\n",
        "    fix_condition_list = taxonomy_df[\"Fix Condition\"].dropna().unique().tolist()\n",
        "    fix_component_list = taxonomy_df[\"Fix Component\"].dropna().unique().tolist()\n",
        "    root_cause_list = taxonomy_df[\"Root Cause\"].dropna().unique().tolist()\n",
        "    text_columns = [\"Complaint\", \"Cause\", \"Correction\"]\n",
        "\n",
        "    for idx, row in complaints_df.iterrows():\n",
        "        all_conditions = []\n",
        "        all_components = []\n",
        "        all_root_causes = []\n",
        "        for col in text_columns:\n",
        "            conditions, components, root_causes = extract_conditions_from_text(\n",
        "                row[col],\n",
        "                symptom_condition_list,\n",
        "                symptom_component_list,\n",
        "                fix_condition_list,\n",
        "                fix_component_list,\n",
        "                root_cause_list\n",
        "            )\n",
        "            all_conditions.extend(conditions)\n",
        "            all_components.extend(components)\n",
        "            all_root_causes.extend(root_causes)\n",
        "        all_conditions = list(dict.fromkeys(all_conditions))\n",
        "        all_components = list(dict.fromkeys(all_components))\n",
        "        all_root_causes = list(dict.fromkeys(all_root_causes))\n",
        "        for i in range(min(3, len(all_conditions))):\n",
        "            complaints_df.at[idx, f\"Symptom Condition {i+1}\"] = all_conditions[i]\n",
        "        for i in range(min(3, len(all_components))):\n",
        "            complaints_df.at[idx, f\"Symptom Component {i+1}\"] = all_components[i]\n",
        "        fix_conditions = [c for c in all_conditions if c in fix_condition_list]\n",
        "        fix_components = [c for c in all_components if c in fix_component_list]\n",
        "\n",
        "        for i in range(min(3, len(fix_conditions))):\n",
        "            complaints_df.at[idx, f\"Fix Condition {i+1}\"] = fix_conditions[i]\n",
        "\n",
        "        for i in range(min(3, len(fix_components))):\n",
        "            complaints_df.at[idx, f\"Fix Component {i+1}\"] = fix_components[i]\n",
        "\n",
        "\n",
        "        if all_root_causes:\n",
        "            complaints_df.at[idx, \"Root Cause\"] = all_root_causes[0]\n",
        "    columns_to_fill = [f\"{prefix} {i+1}\" for prefix in\n",
        "                      [\"Symptom Condition\", \"Symptom Component\", \"Fix Condition\", \"Fix Component\"]\n",
        "                      for i in range(3)]\n",
        "    columns_to_fill.append(\"Root Cause\")\n",
        "\n",
        "    for col in columns_to_fill:\n",
        "        complaints_df[col] = complaints_df[col].fillna(\"Unknown\")\n",
        "\n",
        "    return complaints_df"
      ],
      "metadata": {
        "id": "Cb79pvztYIBs"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main execution\n",
        "if 'complaints_df' in globals() and 'taxonomy_df' in globals():\n",
        "    # Process the data\n",
        "    tagged_complaints_df = process_complaints_data(complaints_df.copy(), taxonomy_df)\n",
        "\n",
        "    # Save to Excel\n",
        "    tagged_complaints_df.to_excel(\"Tagged_Data_Enhanced.xlsx\", index=False)\n",
        "    print(\"Data processing completed and saved to Tagged_Data_Enhanced.xlsx\")\n",
        "else:\n",
        "    print(\"Error: complaints_df and taxonomy_df must be defined before processing.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6p9aaq8YMnP",
        "outputId": "b262254a-fa9a-4ace-ccb4-686c3246e3f1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-050af133386d>:40: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  taxonomy_df = taxonomy_df.applymap(lambda x: str(x).strip().lower() if isinstance(x, str) else x)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data processing completed and saved to Tagged_Data_Enhanced.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Thank you for your patience and understanding...!**"
      ],
      "metadata": {
        "id": "vG_nieWaYWZH"
      }
    }
  ]
}